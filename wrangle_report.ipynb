{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h1> DATA WRANGLING REPORT</h1>\n",
    " <h2> ONI OLUWASEGUN YEMI </h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedure for the data wrangling is highlighted and explained below:\n",
    "## 1. Gathering the Data :\n",
    "    \n",
    " > We have used the following three pieces of data in a Jupyter Notebook titled wrangle_act.ipynb:\n",
    "   \n",
    "  a. The “WeRateDogs” Twitter archive.The file was downloaded manually. Link : data/twitter_archive_enhanced.csv\n",
    "      \n",
    "  b. The Tweet Image Predictions.This file (image_predictions.tsv) is hosted on Udacity's servers and was\n",
    "        downloaded programmatically using the Requests,and beautifulSoup library and the following\n",
    "        URL:https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\n",
    "        \n",
    "  c. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Assessing the Data :\n",
    "   ● Quality issues\n",
    "### Quality issues\n",
    "\n",
    "1. incorrect datatype, timestamp and tweet_id\n",
    "\n",
    "2. inavlid dog name (dog name corresponding to english stopwords and None) \n",
    "\n",
    "3. To retain the original tweets: the non-null data in columns (in_reply_to_status_id\", \"in_reply_to_user_id\", \"retweeted_status_id\", \"retweeted_status_user_id\", \"retweeted_statud_timestamp\") needs to be deleted or supressed \n",
    "\n",
    "4. The source column contains html tags \n",
    "\n",
    "5. Some denominator ratings are either above or less than 10  \n",
    "\n",
    "6. some numerator ratings are outrageous, while some  are false (decimals) and not properly scrapped\n",
    "\n",
    "7. A total of 639 double links are present within \"expanded_urls\" column data \n",
    "\n",
    "8. Incorrect urls (not correspodning to twitter ratings)\n",
    "\n",
    "\n",
    "   ● Tidiness issues\n",
    "1. The variables doggo, floofer, pupper and puppo present in the image_prediction table, all represent one single variable and based on the tidyness rule, should be a part of a single column\n",
    "\n",
    "2. All the three tables should be combined into one i.e a master dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cleaning the data\n",
    " * Issue #1: The variables doggo, floofer, pupper and puppo present in the image_prediction table, all represent one single variable and based on the tidyness rule, should be a part of a single column\n",
    "     - Define: Melt the doggo, floofer, puper and puppo columns to a *dogs* and *stages*\n",
    " * Issue #2: All the three tables should be combined into one i.e a master dataframe.\n",
    "     - Define: Merge all the three datasets together using the tweet_id column \n",
    " * Issue #3: Incorrect data type; Timestamps and tweet_id \n",
    "     - Define: Convert the timestamps to date and the tweet_id to string \n",
    " * Issue #4: To retain the original tweets: the non-null data in columns (in_reply_to_status_id\", \"in_reply_to_user_id\", \"retweeted_status_id\", \"retweeted_status_user_id\", \"retweeted_statud_timestamp\") needs to be deleted or supressed \n",
    "     - Define: Drop the Unneeded rows and columns \n",
    " * Issue #5: inavlid dog name (dog name corresponding to english stopwords and None)\n",
    "     - Define:  All invalid dog names are lowercase, therefore, all lowercase names should be deleted  \n",
    " * Issue #6:  Some denominator ratings are either above or less than 10\n",
    "     - Define: Replace all denominator rating by the median rating which is 10\n",
    " * Issue #7: Some numerator ratings are outrageous, while some  are false (decimals) and not properly scrapped\n",
    "     - Define: Replace the wrongly scrapped values and replace any other outrageous ratings with the median   \n",
    " * Issue #8: The source column contains html tags \n",
    "     - Define: use the strip function to remove the html tags \n",
    " * Issue #9:  A total of 639 double links are present within \"expanded_urls\" column data \n",
    "     - Define: Remove the second link in the expanded url colum\n",
    " * Issue:#10  Incorrect urls (not correspodning to twitter ratings)\n",
    "     - Define:  Filter out urls that does'nt conform to twitter real ratings\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Storing Data and Reports\n",
    "    ● The cleansed data is stored in 'data/twitter_archive_master.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. References\n",
    "    \n",
    "[Panda column with loop:](https://chrisalbon.com/python/data_wrangling/pandas_create_column_with_loop/)\n",
    "\n",
    "[Suppress HTML:](https://stackoverflow.com/questions/13682044/pandas-dataframe-remove-unwanted-parts-from-strings-in-a-column/)\n",
    "\n",
    "[from try/except:](https://wiki.python.org/moin/HandlingExceptions)\n",
    "    \n",
    "[Replace column:](https://github.com/pandas-dev/pandas/issues/9106)\n",
    "    \n",
    "[stop-words:](https://martinapugliese.github.io/english-stopwords/)\n",
    "    \n",
    "[Convert markdown to pdf:](http://markdown2pdf.com/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
